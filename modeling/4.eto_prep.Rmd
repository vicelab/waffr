---
title: "CWU calulations"
author: "asmtry"
output: html_document
---

```{r setupKnitr, include = FALSE}
knitr::opts_knit$set(echo = TRUE, root.dir = 'D:/lbooth/wfar', warning = TRUE, collapse = TRUE)
#knitr::opts_chunk$set(cache=TRUE)
```

```{r setupEnv, include=FALSE}
source("R/utilities.R")
source("R/Kc.R")
source("R/eto.R")

pkgTest("rgdal", "raster", "tools", "lubridate", "parallel")
rasterOptions(progress = "text", tmpdir = "B:/tmp", time = TRUE)
# rasterOptions(todisk = TRUE)
# rasterOptions(progress = "text", tmpdir = "tmpdir", time = TRUE)
```

```{r importData}
# ca_boundary defines the boundary for the area/(s) of analysis (includes counties)
# ca_boundary <- readOGR("Input/SHAPEFILES/cb_2014_CA_5m.shp", layer="cb_2014_CA_5m")
ca_boundary.path <- "Input/SHAPEFILES/cnty24k09/cnty24k09_state_poly_s100.shp"
eto.dir <- "input/SPATIALCIMIS"
eto.crs <- CRS("+init=epsg:3310")
```

To perform operations on collections of daily ETo layers, we can stack each raster file 
```{r prepareAnalysis}
eto.paths <- list.files(path=eto.dir, pattern=".(asc)$", full.names=T, recursive=TRUE)

eto.table <- data.frame(
  abs_path = eto.paths,
  source = sapply(strsplit(file_path_sans_ext(eto.paths),"/"),'[[',2),
  product_name = sapply(strsplit(file_path_sans_ext(eto.paths),"/"),'[[',6),
  date = as.Date(regmatches(eto.paths,regexpr("(?<=SPATIALCIMIS)(.*)(?=ETo.asc)",eto.paths, perl=TRUE)), format="/%Y/%m/%d/"),
  stringsAsFactors = FALSE
)

eto.table["w.year"] <- as.Date(waterYearlt(eto.table$date))

eto.table["minval"] <- sapply(eto.table[["abs_path"]], 
                              function(x) minValue(setMinMax(raster(x))))
eto.table["maxval"] <- sapply(eto.table[["abs_path"]], 
                              function(x) maxValue(setMinMax(raster(x))))

eto.table[c("xres", "yres", "minval", "maxval")] <- sapply(eto.table[["abs_path"]], 
                              function(x) {
                                x <- setMinMax(raster(x))
                                return(c(xres(x),yres(x),minValue(x),maxValue(x)))
                                })

# Tag (x,y)[min,max,res], ncell, and nlayers if applicable
eto.table <- rtTagParam(eto.table)
# Tag anomalous parameters according to metadata parameters specified
eto.table["anoml"] <- tagAnomalous(eto.table, c("xmin", "xmax", "ymin", "ymax", "ncell", "xres", "yres"), modal)

rm(eto.paths)

```

```{r dataInspection}
anom.table <- makeAnomtable(eto.table)
anom.indicies <- unique(which(anom.table==TRUE, arr.ind = TRUE)[,1])
anom.table <- cbind(eto.table[anom.indicies,], anom.table[anom.indicies,])

# At this point, we visually inspect anom.indicies and perform manual cleaning depending on what the problem is

# (x,y)[res]
# 2012-06-25 is the only one with an anomalous resolution (500m vs 2000m)'

# (x,y)[min,max]
# The rest appear to be missing a couple of rows or columns worth of data

# Limit our analysis to 2007-2016
eto.table <- eto.table[!(year(eto.table[["date"]])<2007),]
seq(ymd("2007-01-01"), ymd("2016-12-31"), by = "day")
missing.date.index <- !(seq(ymd("2007-01-01"), ymd("2016-12-31"), by = "day") %in% eto.table[["date"]])
missing.dates <- seq(ymd("2007-01-01"), ymd("2016-12-31"), by = "day")[missing.date.index]
warning(paste0("Missing dates: "), missing.dates, "will be set to the last complete observation.")

filled.obs <- as.data.frame(lapply(eto.table[eto.table[["date"]] == missing.dates[1]-1,], rep, length(missing.dates)))
filled.obs[["date"]] <- missing.dates
eto.table <- rbind(eto.table,filled.obs)
rm(filled.obs, missing.dates, missing.date.index)
```

As there is nothing major amiss, the resolution and minor extent issues can be resolved by `resample`-ing, which is required for upscaling anyway.



## Round ETo
This is a very quick step. Completes in under 10 minutes on 22 threads.
```{r}
scale_eto <- function(abs_path, eto.crs, source, date) {
  dir.create(paste0("output/cleaned_inputs/", source, "_scaled/", year(date)), recursive = TRUE, showWarnings = FALSE)
  outpath <- paste0("output/cleaned_inputs/", source, "_scaled/", year(date), "/", format(date, format="%Y_%m_%d"), ".tif")
  calc(raster(abs_path, crs = eto.crs), fun=function(x){round(x * 100)},
       format = "GTiff", progress = "text", 
       datatype = "INT2U", overwrite = TRUE, filename = outpath)
}

# Make only as many clusters as necessary, bound by available cores
cl <- makeCluster(min((detectCores() - 2), nrow(eto.table)), outfile = "debug.txt")
clusterExport(cl, list("eto.table", "scale_eto"))
clusterEvalQ(cl,{library(raster)
  library(lubridate)})
clusterEvalQ(cl, rasterOptions(progress = "text", time = TRUE))
parRapply(cl, eto.table,  
       function(x) 
         scale_eto(x[["abs_path"]], CRS("+init=epsg:3310"), x[["source"]], x[["date"]]))
stopCluster(cl)
```

## 2.2 Import and re-inspect rounded rasters
```{r loadCleaned}
# Load cleaned files into file table
# TODO: DRY
eto.paths.scaled <- list.files(path="output/cleaned_inputs/SPATIALCIMIS_scaled", pattern=".(tif)$", full.names=T, recursive=TRUE)

# TODO: remove hardcoded gsub
eto.table.scaled <- data.frame(
  abs_path = eto.paths.scaled,
  source = sapply(strsplit(file_path_sans_ext(eto.paths.scaled),"/"),'[[',3),
  product_name = "ETo",
  date = as.Date(sapply(strsplit(file_path_sans_ext(eto.paths.scaled),"/"),'[[',5), format="%Y-%m-%d"),
  stringsAsFactors = FALSE
)

rm(eto.paths.scaled, eto.table)
```

## Warp ETo
```{r, eval=FALSE, include=FALSE}
# This is a test run of the function to be applied to make sure that it works as expected
gdalwarp_wrapper("bin/gdal/apps/gdalwarp.exe",
                 "-s_srs EPSG:3310 -t_srs EPSG:3310 -tr 30 30 -r bilinear -overwrite -crop_to_cutline -co \"COMPRESS=LZW\" -co \"PREDICTOR=2\" -wm 2000 --config GDAL_CACHEMAX 2000", 
                 ca_boundary.path, eto.table.scaled[1,1], "output/testout.tif")
```

```{r}
warp_eto <- function(abs_path, cut.shapefile, source, date) {
  dir.create(paste0("E:/Users/lbooth/Documents/wfar/output/cleaned_inputs/", source, "_projected/", year(date)), recursive = TRUE, showWarnings = FALSE)
  outpath <- paste0("E:/Users/lbooth/Documents/wfar/output/cleaned_inputs/", source, "_projected/", year(date), "/", format(date, format="%Y_%m_%d"), ".tif")
  gdalwarp_wrapper("bin/gdal/apps/gdalwarp.exe",
                 "-s_srs EPSG:3310 -t_srs EPSG:3310 -tr 30 30 -r bilinear -overwrite -crop_to_cutline -co \"COMPRESS=LZW\" -co \"PREDICTOR=2\" -wm 2000 --config GDAL_CACHEMAX 2000", 
                 cut.shapefile, abs_path, outpath)
}

# Make only as many clusters as necessary, bound by available cores
cl <- makeCluster(20, outfile = "debug.txt")
clusterExport(cl, list("eto.table.scaled", "warp_eto", "ca_boundary.path", "gdalwarp_wrapper"))
clusterEvalQ(cl,{library(raster)
  library(lubridate)})
clusterEvalQ(cl, rasterOptions(progress = "text", time = TRUE))
parRapply(cl, eto.table.scaled,  
       function(x) 
         warp_eto(x[["abs_path"]], ca_boundary.path, x[["source"]], x[["date"]]))
stopCluster(cl)
```
Started at 16:11 finished at 23:01. 7 hrs on ts-03, 20 h-threads allocated